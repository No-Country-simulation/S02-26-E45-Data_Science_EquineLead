{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e6a7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE = \"https://www.horseclicks.com\"\n",
    "\n",
    "FILTER_PATH = (\n",
    "    \"/for-sale?page=2\"\n",
    ")\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "def get_soup(url):\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    return BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "def scrape_listings(max_pages=2, sleep_seconds=5):\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for page in tqdm(range(1, max_pages+1), total=max_pages, desc=\"Pages\", leave=True, position=0):\n",
    "        url = f\"{BASE}/horses{FILTER_PATH.format(page=page)}\"\n",
    "        print(f\"Scraping page {page}: {url}\")\n",
    "\n",
    "        soup = get_soup(url)\n",
    "\n",
    "        links = soup.select(\"div.al-listings-item.is-item\")\n",
    "        listing_urls = set()\n",
    "\n",
    "        for div in links:\n",
    "            href = div.get(\"href\")\n",
    "            if not href:\n",
    "                continue\n",
    "\n",
    "            url = BASE+href\n",
    "            print(url)\n",
    "            return\n",
    "\n",
    "            listing_urls.add(url)\n",
    "\n",
    "        for lurl in tqdm(listing_urls, total=len(listing_urls), desc=\"Horse Profiles\", leave=False, position=0):\n",
    "            try:\n",
    "                data = {}\n",
    "                data[\"horse_id\"] = lurl.split(\"-\")[-1]\n",
    "                \n",
    "                #Caracteristicas del caballo\n",
    "                lsoup = get_soup(lurl).body\n",
    "                ul_features_horse = lsoup.select_one(\"ul.meta-data.list-unstyled\")\n",
    "\n",
    "                \n",
    "                for dl in ul_features_horse.select(\"dl.row\"):\n",
    "                    key = dl.find(\"dt\").get_text(strip=True)\n",
    "                    value = dl.find(\"dd\").get_text(strip=True)\n",
    "\n",
    "                    data[key] = value\n",
    "                \n",
    "                # Location\n",
    "                h5_location = lsoup.select_one(\"div.col-xs-12.col-sm-5.no-padding-xs div header h5\")\n",
    "                location = h5_location.get_text(strip=True) if h5_location else None\n",
    "\n",
    "                # Price\n",
    "                span_price = lsoup.select_one(\"span.item-price\")\n",
    "                price = span_price.get_text(strip=True) if span_price else None\n",
    "\n",
    "                # Skills / Disciplines\n",
    "                dl = lsoup.find(\"dt\", string=\"Skills / Disciplines\")\n",
    "                skills_disciplines = None\n",
    "                if dl:\n",
    "                    dd = dl.find_next_sibling(\"dd\")\n",
    "                    skills_disciplines = dd.get_text(strip=True) if dd else None\n",
    "                    \n",
    "                # Additional comments (span[itemprop=\"description\"])\n",
    "                desc_span = lsoup.select_one('div.well p span[itemprop=\"description\"]')\n",
    "                additional_comments = desc_span.get_text(strip=True) if desc_span else None\n",
    "\n",
    "                # Shipping (segundo <p> después de div.well)\n",
    "                p_shipping = lsoup.select_one(\"div.well p ~ p\")\n",
    "                shipping = p_shipping.get_text(strip=True) if p_shipping else None\n",
    "\n",
    "                # Company name (h4)\n",
    "                h4_cn = lsoup.select_one(\"div.well h4\")\n",
    "                company_name = h4_cn.get_text(strip=True) if h4_cn else None\n",
    "\n",
    "                # Company profile href (primer <a> dentro de los <p> después de h4)\n",
    "                a_cp = lsoup.select_one(\"div.well h4 + p ~ p a\")\n",
    "                company_profile = a_cp.get(\"href\") if a_cp else None\n",
    "\n",
    "                data[\"Location\"] = location\n",
    "                data[\"Price\"] = price\n",
    "                data[\"Horse Profile\"] = lurl\n",
    "                data[\"Skills\"] = skills_disciplines\n",
    "                data[\"Comments\"] = additional_comments\n",
    "                data[\"Shipping\"] = shipping\n",
    "                data[\"Company Name\"] = company_name\n",
    "                data[\"Company Profile\"] = company_profile\n",
    "\n",
    "                rows.append(data)\n",
    "\n",
    "                sleep(sleep_seconds)  # rate limit suave\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {lurl}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff286f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pages:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1: https://www.horseclicks.com/horses/for-sale?page=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pages:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://www.horseclicks.com/horses/for-sale?page=2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mscrape_listings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df.head()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mscrape_listings\u001b[39m\u001b[34m(max_pages, sleep_seconds)\u001b[39m\n\u001b[32m     35\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/horses\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFILTER_PATH.format(page=page)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScraping page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m soup = \u001b[43mget_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m links = soup.select(\u001b[33m\"\u001b[39m\u001b[33mdiv.al-listings-item.is-item\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m listing_urls = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mget_soup\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_soup\u001b[39m(url):\n\u001b[32m     26\u001b[39m     resp = requests.get(url, headers=HEADERS, timeout=\u001b[32m30\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BeautifulSoup(resp.text, \u001b[33m\"\u001b[39m\u001b[33mlxml\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cursos\\NoCountry\\S02-26-E45-Data_Science_EquineLead\\.venv\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://www.horseclicks.com/horses/for-sale?page=2"
     ]
    }
   ],
   "source": [
    "df = scrape_listings(max_pages=100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a038b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892, 25)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d6b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../../data/raw/equinenow_horses_listings.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e9d0cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplaywright\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m async_playwright\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m playwright = \u001b[38;5;28;01mawait\u001b[39;00m async_playwright().start()\n\u001b[32m      4\u001b[39m browser = \u001b[38;5;28;01mawait\u001b[39;00m playwright.chromium.launch(headless = \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m page = \u001b[38;5;28;01mawait\u001b[39;00m browser.new_page()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cursos\\NoCountry\\S02-26-E45-Data_Science_EquineLead\\.venv\\Lib\\site-packages\\playwright\\async_api\\_context_manager.py:51\u001b[39m, in \u001b[36mPlaywrightContextManager.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> AsyncPlaywright:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__aenter__\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cursos\\NoCountry\\S02-26-E45-Data_Science_EquineLead\\.venv\\Lib\\site-packages\\playwright\\async_api\\_context_manager.py:46\u001b[39m, in \u001b[36mPlaywrightContextManager.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m playwright_future.done():\n\u001b[32m     45\u001b[39m     playwright_future.cancel()\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m playwright = AsyncPlaywright(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     47\u001b[39m playwright.stop = \u001b[38;5;28mself\u001b[39m.\u001b[34m__aexit__\u001b[39m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m playwright\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cursos\\NoCountry\\S02-26-E45-Data_Science_EquineLead\\.venv\\Lib\\site-packages\\playwright\\_impl\\_transport.py:120\u001b[39m, in \u001b[36mPipeTransport.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    117\u001b[39m         startupinfo.wShowWindow = subprocess.SW_HIDE\n\u001b[32m    119\u001b[39m     executable_path, entrypoint_path = compute_driver_executable()\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28mself\u001b[39m._proc = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_subprocess_exec(\n\u001b[32m    121\u001b[39m         executable_path,\n\u001b[32m    122\u001b[39m         entrypoint_path,\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrun-driver\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    124\u001b[39m         stdin=asyncio.subprocess.PIPE,\n\u001b[32m    125\u001b[39m         stdout=asyncio.subprocess.PIPE,\n\u001b[32m    126\u001b[39m         stderr=_get_stderr_fileno(),\n\u001b[32m    127\u001b[39m         limit=\u001b[32m32768\u001b[39m,\n\u001b[32m    128\u001b[39m         env=env,\n\u001b[32m    129\u001b[39m         startupinfo=startupinfo,\n\u001b[32m    130\u001b[39m     )\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_error_future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\asyncio\\subprocess.py:224\u001b[39m, in \u001b[36mcreate_subprocess_exec\u001b[39m\u001b[34m(program, stdin, stdout, stderr, limit, *args, **kwds)\u001b[39m\n\u001b[32m    221\u001b[39m loop = events.get_running_loop()\n\u001b[32m    222\u001b[39m protocol_factory = \u001b[38;5;28;01mlambda\u001b[39;00m: SubprocessStreamProtocol(limit=limit,\n\u001b[32m    223\u001b[39m                                                     loop=loop)\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m transport, protocol = \u001b[38;5;28;01mawait\u001b[39;00m loop.subprocess_exec(\n\u001b[32m    225\u001b[39m     protocol_factory,\n\u001b[32m    226\u001b[39m     program, *args,\n\u001b[32m    227\u001b[39m     stdin=stdin, stdout=stdout,\n\u001b[32m    228\u001b[39m     stderr=stderr, **kwds)\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Process(transport, protocol, loop)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\asyncio\\base_events.py:1756\u001b[39m, in \u001b[36mBaseEventLoop.subprocess_exec\u001b[39m\u001b[34m(self, protocol_factory, program, stdin, stdout, stderr, universal_newlines, shell, bufsize, encoding, errors, text, *args, **kwargs)\u001b[39m\n\u001b[32m   1754\u001b[39m     debug_log = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexecute program \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprogram\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m   1755\u001b[39m     \u001b[38;5;28mself\u001b[39m._log_subprocess(debug_log, stdin, stdout, stderr)\n\u001b[32m-> \u001b[39m\u001b[32m1756\u001b[39m transport = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_subprocess_transport(\n\u001b[32m   1757\u001b[39m     protocol, popen_args, \u001b[38;5;28;01mFalse\u001b[39;00m, stdin, stdout, stderr,\n\u001b[32m   1758\u001b[39m     bufsize, **kwargs)\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._debug \u001b[38;5;129;01mand\u001b[39;00m debug_log \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1760\u001b[39m     logger.info(\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m, debug_log, transport)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\asyncio\\base_events.py:528\u001b[39m, in \u001b[36mBaseEventLoop._make_subprocess_transport\u001b[39m\u001b[34m(self, protocol, args, shell, stdin, stdout, stderr, bufsize, extra, **kwargs)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_subprocess_transport\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol, args, shell,\n\u001b[32m    525\u001b[39m                                      stdin, stdout, stderr, bufsize,\n\u001b[32m    526\u001b[39m                                      extra=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    527\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create subprocess transport.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "\n",
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.whatismybrowser.com/detect/what-is-my-user-agent/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s02-26-e45-data-science-equinelead",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
