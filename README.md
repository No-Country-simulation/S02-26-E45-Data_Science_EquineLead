![banner](./assets/equinelead_logo_github.jpg)

# EquineLead: Data-Driven Growth Engine for the Horse Industry

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Prefect](https://img.shields.io/badge/Prefect-ffffff?style=for-the-badge&logo=prefect&logoColor=070E10)
![UV](https://img.shields.io/badge/UV-000000?style=for-the-badge&logo=astral&logoColor=white)
![Google Cloud](https://img.shields.io/badge/Google_Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)
![Playwright](https://img.shields.io/badge/Playwright-2EAD33?style=for-the-badge&logo=playwright&logoColor=white)
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-4E9A06?style=for-the-badge&logo=python&logoColor=white)
![LXML](https://img.shields.io/badge/LXML-A90533?style=for-the-badge&logo=xml&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Apache Parquet](https://img.shields.io/badge/Apache_Parquet-6070AD?style=for-the-badge&logo=apache&logoColor=white)
![Faker](https://img.shields.io/badge/Faker-CF4141?style=for-the-badge&logo=python&logoColor=white)

**EquineLead** es un motor de crecimiento basado en datos dise帽ado para resolver la fragmentaci贸n del mercado ecuestre. Este sistema transforma la navegaci贸n casual en leads calificados mediante la integraci贸n de scrapers inteligentes, embudos automatizados y modelos de propensi贸n de compra.

---

##  Tabla de Contenidos
- [Definici贸n del Problema](#definici贸n-del-problema)
- [Arquitectura y Stack](#arquitectura-del-sistema)
- [Infraestructura (Terraform)](#infraestructura-como-c贸digo-iac)
- [Pipeline de Datos](#pipeline-de-datos-etlelt)
- [Gu铆a de Ejecuci贸n R谩pida](#gu铆a-de-ejecuci贸n-quick-start)

---

## Definici贸n del Problema
### El Desaf铆o
La industria ecuestre opera en un ecosistema nicho, altamente fragmentado y con costos de adquisici贸n (CAC) elevados. Actualmente, identificar a un comprador de un caballo de salto de $50,000 frente a un entusiasta casual es una tarea manual e ineficiente.

### Objetivos del Proyecto
+ **Identificaci贸n de Leads de Alto Valor**: Clasificar autom谩ticamente usuarios en los cuatro verticales: Eventos, Servicios, Caballos y Equipamiento.
+ **Reducci贸n del Ciclo de Venta**: Acortar el tiempo entre el "inter茅s inicial" y la "calificaci贸n (SQL)" mediante scoring predictivo.
+ **Optimizaci贸n de B2B y B2C**: Diferenciar el comportamiento de propietarios individuales frente a administradores de centros h铆picos o mayoristas.

### KPIs de xito
+ **Lead Quality Score (LQS)**: Precisi贸n del modelo para predecir la conversi贸n (Meta: >80%).
+ **CAC Reduction**: Reducci贸n esperada del 15% en costos de marketing mediante segmentaci贸n precisa.
+ **Conversion Rate (CVR)**: Mejora del flujo de ventas en el vertical de "Caballos de Alto Valor".

---

## Arquitectura del Sistema
El proyecto est谩 dise帽ado bajo principios de Modern Data Stack, priorizando la velocidad de ejecuci贸n y la observabilidad.

###  Stack Tecnol贸gico

+ **Orquestaci贸n**: Prefect (Local + Prefect Cloud).
+ **Gesti贸n de Entorno**: UV (Instalaci贸n de dependencias 70% m谩s r谩pida que pip).
+ **Contenerizaci贸n**: Docker & Docker-compose.
+ **Ingesta**: Playwright (Din谩mico), BeautifulSoup4 (Est谩tico)
+ **Cloud Storage**: Google Cloud Storage (Data Lake en formato Parquet)
+ **Data Synthesis**: Python Faker + Proyecciones de [Rees46 Dataset](https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store).

---

## Infraestructura como C贸digo (IaC)

Para garantizar la reproducibilidad total, la infraestructura de la nube (Google Cloud Storage) se gestiona mediante **Terraform**. Esto permite levantar el Data Lake y configurar los permisos necesarios en segundos.

### Configuraci贸n de Infraestructura

1.  **Requisitos**: Tener instalado [Terraform](https://www.terraform.io/downloads) y el [Google Cloud CLI](https://cloud.google.com/sdk/docs/install).
2.  **Autenticaci贸n**:
    ```powershell
    gcloud auth application-default login
    ```
3.  **Personalizaci贸n**:
    Crea un archivo `infra/terraform/terraform.tfvars` para definir tus variables:
    ```hcl
    project_id           = "tu-id-de-proyecto"
    region               = "us_weast1"
    bucket_name          = "equinelead-datalake"
    storage_class        = "STANDARD"
    service_account_name = "your-admin"
    ```
4.  **Despliegue**:
    ```powershell
    # Inicializar y aplicar cambios
    terraform -chdir=infra/terraform init
    terraform -chdir=infra/terraform validate
    terraform -chdir=infra/terraform plan -out=tfplan
    terraform -chdir=infra/terraform apply "tfplan"
    ```

### Gesti贸n de Credenciales
Una vez completado el `apply`, Terraform generar谩 una Service Account Key. Extr谩ela para que el pipeline de Docker pueda autenticarse:
```powershell
$rawKey = terraform -chdir=infra/terraform output -raw service_account_key
[System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($rawKey)) | Out-File -FilePath "./secrets/gcp-sa-key.json" -Encoding ascii
```
---

## Pipeline de Datos (ETL/ELT)

![pipeline_run](./assets/demo_flow_data_pipeline.png)

### Ingesta y Scraping Paralelizado
El pipeline ejecuta m煤ltiples scrapers de forma concurrente dentro de contenedores Docker:
+ **Playwright**: Para la extracci贸n de datos en sitios din谩micos de subastas y clasificados.
+ **BeautifulSoup4 + lxml**: Para el procesamiento r谩pido de directorios est谩ticos de servicios y eventos.

### Generaci贸n de Datos Sint茅ticos (Behavioral Tracking)
Para simular el comportamiento de usuario, se mapearon los eventos del dataset de Rees46 a un entorno ecuestre ficticio:

+ **Mapeo de Categor铆as**: Los productos electr贸nicos/hogar se transformaron en categor铆as como Sillas de Salto, Suplementos y Publicaciones de Caballos.
+ **Identidades con Faker**: Se generaron perfiles de usuarios 煤nicos (Leads) con historiales de navegaci贸n coherentes.
+ **Proyecci贸n de Eventos**: Se recrearon funnels de conversi贸n (view -> cart -> purchase) para identificar patrones de "Intenci贸n de Compra".

### Limpieza y Carga (GCP)
+ **Transformaci贸n**: Limpieza de strings, normalizaci贸n de datos numericos y manejo de valores nulos en paralelo.
+ **Storage**: Los datos finales se serializan en Parquet para optimizar el peso y la velocidad de consulta, y se suben a un bucket de Google Cloud Storage.

### Diagrama Entidad-Relaci贸n (DER)

```mermaid
erDiagram
    users_info ||--o{ horses_session_info : ""
    users_info ||--o{ product_session_info : ""   
    horses_listings ||--o{ horses_session_info : ""
    products_listings ||--o{ product_session_info : ""

    users_info {
        uuid user_id PK
        varchar name
        varchar gender
        varchar country
        varchar city
        varchar address
        varchar credit_card_info
        varchar email
        varchar phone_number
        json job_info
        varchar device_type
        varchar traffic_source
        date first_seen
    }

    horses_session_info {
        uuid user_id FK
        int horse_id FK
        varchar event_type
        datetime event_time
    }

    product_session_info {
        uuid user_id FK
        int Item_ID FK
        varchar event_type
        datetime event_time
    }

    horses_listings {
        int Horse_ID PK
        varchar Breed
        varchar Name
        varchar Gender
        boolean In_Foal
        float Height_hh
        float Weight_lbs
        varchar Temperament
    }

    products_listings {
        int Item_ID PK
        varchar Name
        int Stock
        text Description
        float Price
        varchar Images
        varchar URL
    }
```

---

## Gu铆a de Ejecuci贸n (Quick Start)
Este proyecto es totalmente reproducible y "Plug & Play".

> Requisitos: Docker y una cuenta en Prefect Cloud (opcional para logs).

#### Clonar el repositorio:

```bash
git clone https://github.com/No-Country-simulation/S02-26-E45-Data_Science_EquineLead
cd S02-26-E45-Data_Science_EquineLead
```
#### Configurar variables de entorno:
Crea un archivo .env con tus credenciales de GCP y el API Key de Prefect.

```bash
PREFECT_API_URL="https://api.prefect.cloud/api/accounts/[ACCOUNT-ID]/workspaces/[WORKSPACE-ID]"
PREFECT_API_KEY="[API-KEY]"
GCP_PROJECT_ID="tu_id_proyecto"
GCP_BUCKET_NAME="tu_nombre_bucket"
GOOGLE_APPLICATION_CREDENTIALS="path_to_credentials_json"
```

#### Loguearte en Prefect Cloud:

```bash
prefect cloud login
```

#### Levantar la infraestructura:

```bash
docker compose --profile pipeline up --build
```

Este comando levantar谩 el agente de Prefect, construira el contenedor e instalar谩 dependencias con UV y disparar谩 el flujo de ingesta.

> *Nota T茅cnica*: Gracias al gestor UV, la construcci贸n de la imagen ignora el overhead de pip, logrando entornos listos en segundos